{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fer_2013.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/batuhanyndny/notebooks/blob/master/fer_2013.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yxdE9axqr26"
      },
      "source": [
        "!mkdir /root/.kaggle/\n",
        "!touch /root/.kaggle/kaggle.json\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!echo '{\"username\":\"batuhanyndny\",\"key\":\"key\"}' > /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWDpf84ZzWng"
      },
      "source": [
        "!mkdir New"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBvI7YTWzhlY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ea59e09-5bf2-45b3-dbc5-16e3f82406ee"
      },
      "source": [
        "cd New/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/New\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWSBw5hTzkCr"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPoFeI__C2Nr",
        "outputId": "dabdd13c-e1ba-4261-fa2d-c952bb304f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!kaggle datasets download -d shawon10/ckplus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading ckplus.zip to /content/New\n",
            "\r  0% 0.00/3.63M [00:00<?, ?B/s]\n",
            "\r100% 3.63M/3.63M [00:00<00:00, 120MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzYlb4VqDFPQ",
        "outputId": "97f4a18e-14e6-482c-c83c-197cd4ef265e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ckplus.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giimFPuKC6SM"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"ckplus.zip\",\"r\") as ref:\n",
        "  ref.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqmatUMGhpIy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24bcb5e9-91f2-459a-ca65-346ec5ef9bea"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ck  CK+48  ckplus.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjF7UEJC0AqD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90731ecf-bb56-4781-fbdb-40a12f33eee0"
      },
      "source": [
        "cd CK+48"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/New/CK+48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3uCCixW0Hro",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6824a86-bb5d-4634-b53b-b09424ac34dc"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "anger  contempt  disgust  fear\thappy  sadness\tsurprise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUBSelM5rai7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdh2Q8AUrfKe",
        "outputId": "1ef745e0-ac4c-4e62-8036-082a8c1a07ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['disgust', 'happy', 'surprise', 'fear', 'sadness', 'anger', 'contempt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sFcUPmqt3n3"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ku2Unbht7nC",
        "outputId": "0454e6df-da37-4fa4-c2d1-d39f52b405f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "paths = os.listdir()\n",
        "import cv2\n",
        "import imageio\n",
        "\n",
        "images = []\n",
        "index = 0\n",
        "for path in paths:\n",
        "  print(\"Loading \",path)\n",
        "  for image in os.listdir(\"{}/\".format(path)):\n",
        "    print(image)\n",
        "    img = imageio.imread(image)\n",
        "    img = np.asarray(img)\n",
        "    input_img_resize = np.resize(input_img,(48,48))\n",
        "    images.append(input_img_resize)\n",
        "    index += 1\n",
        "  print(\"size of \",path,\" is \",index)\n",
        "\n",
        "for dataset in data_dir_list:\n",
        "    img_list=os.listdir(data_path+'/'+ dataset)\n",
        "    print ('Loaded the images of dataset-'+'{}\\n'.format(dataset))\n",
        "    for img in img_list:\n",
        "        input_img=cv2.imread(data_path + '/'+ dataset + '/'+ img )\n",
        "        #input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2GRAY)\n",
        "        input_img_resize=cv2.resize(input_img,(48,48))\n",
        "        img_data_list.append(input_img_resize)\n",
        "\n",
        "img_data = np.array(images)\n",
        "img_data = img_data.astype('float32')\n",
        "img_data = img_data/255\n",
        "img_data.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading  disgust\n",
            "S035_005_00000018.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-868048460a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/content/New/CK+48/S035_005_00000018.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOJkwxWcuNzT"
      },
      "source": [
        "num_of_samples = img_data.shape[0]\n",
        "labels = np.ones((num_of_samples,),dtype='int64')\n",
        "\n",
        "labels[0:177]=0 #disgust\n",
        "labels[178:384]=1 #happy\n",
        "labels[385:633]=2 #surprise\n",
        "labels[634:708]=3 #fear\n",
        "labels[709:792]=4 #sadness\n",
        "labels[793:927]=5 #anger\n",
        "labels[928:981]=6 #contempt\n",
        "\n",
        "names = ['disgust','happy','surprise','fear','sadness','anger','contempt']\n",
        "\n",
        "def getLabel(id):\n",
        "    return ['disgust','happy','surprise','fear','sadness','anger','contempt'][id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U1tmSxO8uQX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cca9118a-1d5a-4114-d6a2-b53e077fe61f"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "\n",
        "Y = np_utils.to_categorical(labels, num_classes)\n",
        "\n",
        "#Shuffle the dataset\n",
        "x,y = shuffle(img_data,Y, random_state=42)\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=2)\n",
        "\n",
        "x_test=X_test\n",
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(833, 1, 48, 48)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sLMWrTAuBwG"
      },
      "source": [
        "# **CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFnma8I5uDyD",
        "outputId": "fb07e8a6-a8dd-4394-c6bf-4b50fa7afd41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_accuracy\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.layers import Activation, Conv2D, Dropout\n",
        "from keras.layers import Dense, BatchNormalization, MaxPooling2D , AveragePooling2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input\n",
        "from keras import layers\n",
        "from keras.regularizers import l2\n",
        "\n",
        "label_count = 7\n",
        "batch_size = 32\n",
        "epochs = 300\n",
        "width, height = 48 , 48 \n",
        "\n",
        "inputShape = (width,height,1)\n",
        "\n",
        "regularizer = l2(0.01)\n",
        "\n",
        "#base \n",
        "img_inp = Input(inputShape)\n",
        "\n",
        "x = Conv2D(1, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=l2(0.01))(img_inp)\n",
        "x = Conv2D(64, (3, 3), padding='same',activation='relu') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = Conv2D(64, (3, 3), padding='same',activation='relu') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = MaxPooling2D(pool_size=(2,2), strides=(2, 2)) (x)\n",
        "x = Dropout(0.5) (x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = Conv2D(128, (3, 3), padding='same', activation='relu') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = MaxPooling2D(pool_size=(2,2)) (x)\n",
        "x = Dropout(0.5) (x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), padding='same', activation='relu') (x)\n",
        "x = BatchNormalization() (x)\n",
        "x = Conv2D(256, (3, 3), padding='same', activation='relu') (x)\n",
        "\n",
        "x = Flatten() (x)\n",
        "\n",
        "x = Dense(512, activation='relu') (x)\n",
        "x = Dropout(0.5) (x)\n",
        "x = Dense(256, activation='relu') (x)\n",
        "x = Dropout(0.5) (x)\n",
        "x = Dense(128, activation='relu') (x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64, activation='relu') (x)\n",
        "x = Dropout(0.5)(x) \n",
        "x = Dense(7, activation='softmax')(x)\n",
        "\n",
        "output = Dense(label_count, activation = 'softmax') (x)\n",
        "\n",
        "# This is the model we will train\n",
        "model = Model(inputs=img_inp, outputs=output)\n",
        "\n",
        "optimizer = Adam(lr = 0.01)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "            optimizer=optimizer, \n",
        "            metrics=['categorical_accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "filepath = \"modelcp.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "trained = model.fit(X_train, y_train, \n",
        "                    batch_size=batch_size, \n",
        "                    epochs=epochs, \n",
        "                    verbose=1, \n",
        "                    validation_data=(np.array(X_valid), np.array(y_valid)), \n",
        "                    shuffle=True,\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "print(\"****************************************************************************\")\n",
        "print(\"train completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_23 (InputLayer)        (None, 48, 48, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 46, 46, 1)         10        \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 46, 46, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_99 (Batc (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_120 (Conv2D)          (None, 46, 46, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_100 (Bat (None, 46, 46, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_81 (Dropout)         (None, 23, 23, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_121 (Conv2D)          (None, 23, 23, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_101 (Bat (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_122 (Conv2D)          (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_102 (Bat (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_123 (Conv2D)          (None, 23, 23, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_103 (Bat (None, 23, 23, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_36 (MaxPooling (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_82 (Dropout)         (None, 11, 11, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_124 (Conv2D)          (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_104 (Bat (None, 11, 11, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_125 (Conv2D)          (None, 11, 11, 256)       590080    \n",
            "_________________________________________________________________\n",
            "flatten_23 (Flatten)         (None, 30976)             0         \n",
            "_________________________________________________________________\n",
            "dense_102 (Dense)            (None, 512)               15860224  \n",
            "_________________________________________________________________\n",
            "dropout_83 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_103 (Dense)            (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_84 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_104 (Dense)            (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_85 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_105 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_86 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_106 (Dense)            (None, 7)                 455       \n",
            "_________________________________________________________________\n",
            "dense_107 (Dense)            (None, 7)                 56        \n",
            "=================================================================\n",
            "Total params: 17,328,137\n",
            "Trainable params: 17,326,601\n",
            "Non-trainable params: 1,536\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-5f5ecf8f0a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"****************************************************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_23 to have shape (48, 48, 1) but got array with shape (1, 48, 48)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAXxVdfeuvhR"
      },
      "source": [
        "# **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsBj7OlIuYe-"
      },
      "source": [
        "from keras.preprocessing.image import img_to_array\n",
        "import imutils\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.models import model_from_json\n",
        "\n",
        "# parameters for loading data and images\n",
        "detection_model_path = '/anaconda3/pkgs/libopencv-3.4.2-h7c891bd_1/share/OpenCV/haarcascades/haarcascade_frontalface_default.xml' #gonna change\n",
        "loaded_model = load_model(\"modelcp.h5\")\n",
        "\n",
        "\n",
        "# hyper-parameters for bounding boxes shape\n",
        "# loading models\n",
        "face_detection = cv2.CascadeClassifier(detection_model_path)\n",
        "emotion_classifier = loaded_model\n",
        "EMOTIONS = [\"angry\" ,\"disgust\",\"scared\", \"happy\", \"sad\", \"surprised\",\n",
        " \"neutral\"]\n",
        "\n",
        "\n",
        "#feelings_faces = []\n",
        "#for index, emotion in enumerate(EMOTIONS):\n",
        "   # feelings_faces.append(cv2.imread('emojis/' + emotion + '.png', -1))\n",
        "\n",
        "# starting video streaming\n",
        "cv2.namedWindow('your_face')\n",
        "camera = cv2.VideoCapture(0)\n",
        "while True:\n",
        "    frame = camera.read()[1]\n",
        "    #reading the frame\n",
        "    frame = imutils.resize(frame,width=300)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_detection.detectMultiScale(gray,scaleFactor=1.1,minNeighbors=5,minSize=(30,30),flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "    \n",
        "    canvas = np.zeros((250, 300, 3), dtype=\"uint8\")\n",
        "    frameClone = frame.copy()\n",
        "    if len(faces) > 0:\n",
        "        faces = sorted(faces, reverse=True,\n",
        "        key=lambda x: (x[2] - x[0]) * (x[3] - x[1]))[0]\n",
        "        (fX, fY, fW, fH) = faces\n",
        "                    # Extract the ROI of the face from the grayscale image, resize it to a fixed 28x28 pixels, and then prepare\n",
        "            # the ROI for classification via the CNN\n",
        "        roi = gray[fY:fY + fH, fX:fX + fW]\n",
        "        roi = cv2.resize(roi, (48,48))\n",
        "        roi = roi.astype(\"float\") / 255.0\n",
        "        roi = img_to_array(roi)\n",
        "        roi = np.expand_dims(roi, axis=0)\n",
        "        \n",
        "        \n",
        "        preds = emotion_classifier.predict(roi)[0]\n",
        "        emotion_probability = np.max(preds)\n",
        "        label = EMOTIONS[preds.argmax()]\n",
        "\n",
        " \n",
        "    for (i, (emotion, prob)) in enumerate(zip(EMOTIONS, preds)):\n",
        "                # construct the label text\n",
        "                text = \"{}: {:.2f}%\".format(emotion, prob * 100)\n",
        "\n",
        "                # draw the label + probability bar on the canvas\n",
        "               # emoji_face = feelings_faces[np.argmax(preds)]\n",
        "\n",
        "                \n",
        "                w = int(prob * 300)\n",
        "                cv2.rectangle(canvas, (7, (i * 35) + 5),\n",
        "                (w, (i * 35) + 35), (0, 0, 255), -1)\n",
        "                cv2.putText(canvas, text, (10, (i * 35) + 23),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45,\n",
        "                (255, 255, 255), 2)\n",
        "                cv2.putText(frameClone, label, (fX, fY - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
        "                cv2.rectangle(frameClone, (fX, fY), (fX + fW, fY + fH),\n",
        "                              (0, 0, 255), 2)\n",
        "#    for c in range(0, 3):\n",
        "#        frame[200:320, 10:130, c] = emoji_face[:, :, c] * \\\n",
        "#        (emoji_face[:, :, 3] / 255.0) + frame[200:320,\n",
        "#        10:130, c] * (1.0 - emoji_face[:, :, 3] / 255.0)\n",
        "\n",
        "\n",
        "    cv2.imshow('your_face', frameClone)\n",
        "    cv2.imshow(\"Probabilities\", canvas)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "camera.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}